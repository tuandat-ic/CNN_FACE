# -*- coding: utf-8 -*-
"""Untitled29.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QL1sE6IlPHliMzV0M-iimTfAJ_qchcVB
"""

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 1) Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

import os
src_path = "/content/drive/MyDrive/data_mau"

# Kiểm tra thư mục
print("Classes:", os.listdir(src_path))

# 2) Import + tạo generator với resize 60x60 và tách validation 20%
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,  # 20% ảnh làm validation
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

train_generator = datagen.flow_from_directory(
    src_path,
    target_size=(60, 60),
    batch_size=32,
    class_mode='categorical',
    subset='training',   # train subset
    shuffle=True
)

val_generator = datagen.flow_from_directory(
    src_path,
    target_size=(60, 60),
    batch_size=32,
    class_mode='categorical',
    subset='validation',  # validation subset
    shuffle=False
)

# 3) Build CNN model
from tensorflow.keras import layers, models

num_classes = train_generator.num_classes

model = models.Sequential([
    layers.Input(shape=(60, 60, 3)),
    layers.Conv2D(32, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(num_classes, activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

# 4) Train model
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs= 100
)
model.save('final_model.h5')

# =============================
# FIX: Đồng bộ nhãn model <-> tên hiển thị <-> mô tả (robust)
# Dán nguyên vào Colab và chạy
# =============================

from google.colab import files
import os, json, unicodedata, glob
import numpy as np
import matplotlib.pyplot as plt
import gradio as gr
from PIL import Image
from tensorflow.keras.models import load_model

# ---------- Cấu hình (chỉ đổi model_path nếu cần) ----------
model_path = "final_model.h5"
# Nếu bạn có fallback labels vì chắc chắn biết thứ tự model training, giữ trong labels_fallback.
# Nhưng code sẽ ưu tiên tìm class_indices từ train_generator nếu có.
labels_fallback = ["NHUAN", "LINH", "DAT"]

# Nếu bạn đã có face_info (mô tả) với key dạng có dấu hoặc không dấu,
# paste vào đây chính xác như bạn đã viết (mình sẽ auto map).
face_info_user = {
    "NHUẬN": "Hoàng Nhuận với MSSV 31241024710, là một người đam mê công nghệ và thể thao. Nam thường dành thời gian để học tập, tìm hiểu về các mạch điện và hệ thống thông minh và cũng tham gia các trận bóng chuyền sôi động. Về ngoại hình, mình cao khoảng 170 cm và nặng 80 kg. Là một người sống hòa đồng, sôi nổi, nhiệt tình, luôn sẵn sàng lắng nghe và hỗ trợ bạn bè trong học tập và các dự án sáng tạo.",
    "LINH": "Thùy Linh, hiện là sinh viên với MSSV 31241023167. Linh có niềm đam mê với đọc sách và chơi cầu lông, và thường dành thời gian rảnh để khám phá thêm những kỹ năng mới hoặc thử sức với những trò chơi sáng tạo. Về ngoại hình, mình cao khoảng 160 cm và nặng 48 kg. Mình là người hòa đồng, thích kết nối với mọi người và luôn sẵn sàng tham gia các hoạt động nhóm hoặc dự án mới để trải nghiệm và phát triển bản thân.",
    "ĐẠT": "Tuấn Đạt – MSSV 31241021943 – là một người trẻ đầy nhiệt huyết, luôn nuôi dưỡng niềm đam mê với công nghệ và thể thao. Ngoài giờ học, Đạt thường dành thời gian để khám phá tri thức mới, tìm hiểu về cuộc sống và mở rộng góc nhìn. Với ngoại hình cân đối (cao khoảng 1m70, nặng 65kg), Đạt mang phong thái năng động, khỏe khoắn. Trong giao tiếp, Đạt được biết đến là người hòa đồng, sôi nổi và nhiệt tình. Không chỉ hăng hái tham gia hoạt động tập thể, Đạt còn luôn sẵn sàng lắng nghe, chia sẻ và hỗ trợ bạn bè trong học tập cũng như các dự án sáng tạo."
}

# Nếu bạn muốn hiển thị tên có dấu (đẹp) khác với nhãn gốc, khai báo ở đây.
# Key phải là nhãn gốc (như 'NHUAN'), value là tên hiển thị 'NHUẬN'.
label_display_user = {
    "NHUAN": "NHUẬN",
    "LINH": "LINH",
    "DAT": "ĐẠT"
}

# ----------------- Helpers -----------------
def norm_nfc(s):
    if s is None:
        return None
    return unicodedata.normalize("NFC", str(s)).strip()

def remove_diacritics(s):
    if s is None:
        return None
    s = unicodedata.normalize("NFD", str(s))
    return "".join(ch for ch in s if not unicodedata.combining(ch))

# Load model
print("Loading model:", model_path)
model = load_model(model_path)
print("Model loaded.")

# ----------------- Tìm labels theo index (an toàn) -----------------
def build_labels_by_index():
    # 1) Nếu train_generator có sẵn trong scope (nếu bạn đang chạy cell trước đã tạo train_generator)
    try:
        if 'train_generator' in globals():
            ci = train_generator.class_indices
            print("Found train_generator.class_indices:", ci)
            # build list index -> label
            max_idx = max(ci.values()) if len(ci)>0 else -1
            labels_by_index = [None]*(max_idx+1)
            for k,v in ci.items():
                labels_by_index[v] = k
            return labels_by_index
    except Exception as e:
        print("train_generator lookup error:", e)

    # 2) Try loading class_indices.json if exists
    for fname in ["class_indices.json", "class_indices.txt", "class_indices.pkl"]:
        if os.path.exists(fname):
            try:
                with open(fname, "r", encoding="utf-8") as f:
                    data = json.load(f)
                # expect dict label->index
                max_idx = max(data.values())
                labels_by_index = [None]*(max_idx+1)
                for k,v in data.items():
                    labels_by_index[v] = k
                print("Loaded class indices from", fname)
                return labels_by_index
            except Exception:
                pass

    # 3) Try scanning folders common: 'train', 'data', 'dataset'
    for d in ["./train", "./data", "./dataset", "./training", "./images"]:
        if os.path.isdir(d):
            sub = [name for name in os.listdir(d) if os.path.isdir(os.path.join(d,name))]
            if sub:
                sub_sorted = sorted(sub)
                print("Found training subfolders in", d, "->", sub_sorted)
                # CAVEAT: order might not match original training but best-effort
                return sub_sorted

    # 4) Fallback to labels_fallback if defined
    if labels_fallback and isinstance(labels_fallback, list):
        print("Using labels_fallback (developer-provided):", labels_fallback)
        return labels_fallback

    # 5) Last resort: build generic names from number of classes model outputs
    try:
        # pass a dummy through model to get output size
        dummy = np.zeros((1,60,60,3), dtype=np.float32)
        preds = model.predict(dummy)
        n = preds.shape[1]
        generic = [f"class_{i}" for i in range(n)]
        print("No labels found; using generic labels:", generic)
        return generic
    except Exception as e:
        print("Unable to infer labels_by_index:", e)
        return []

labels_by_index = build_labels_by_index()
labels_by_index = [norm_nfc(lbl) for lbl in labels_by_index]  # normalize
print("Labels by index (final):", labels_by_index)

# ----------------- Chuẩn hoá face_info và map keys -----------------
# Normalize user's face_info keys for flexible matching
face_info_norm_map = {}   # key_norm -> (orig_key, value)
for k,v in face_info_user.items():
    kn = norm_nfc(k)
    face_info_norm_map[kn] = (k, v)

# Build ascii (no-diacritics) map to match NHUẬN <-> NHUAN
face_info_ascii_map = {}
for kn, (origk, val) in face_info_norm_map.items():
    ascii_k = remove_diacritics(kn).upper().strip()
    face_info_ascii_map[ascii_k] = (origk, val)

# Normalize label_display
label_display_norm = {}
for k,v in label_display_user.items():
    label_display_norm[norm_nfc(k)] = v

# Final mapping: label_raw -> description
final_face_info = {}
mapping_debug = []  # list of tuples for print: (label_raw, matched_key_used or None, how)

for lbl in labels_by_index:
    lbl_n = norm_nfc(lbl)
    lbl_ascii = remove_diacritics(lbl_n).upper().strip()

    matched = None
    how = None

    # 1) Exact match by normalized key (face_info has key identical to label raw)
    if lbl_n in face_info_norm_map:
        matched = face_info_norm_map[lbl_n][1]
        how = "exact_norm"
    else:
        # 2) Match by ascii (remove diacritics)
        if lbl_ascii in face_info_ascii_map:
            matched = face_info_ascii_map[lbl_ascii][1]
            how = "matched_by_ascii"
        else:
            # 3) Try matching by label_display value if user used display name as key in face_info
            disp = label_display_norm.get(lbl_n)
            if disp:
                disp_norm = norm_nfc(disp)
                disp_ascii = remove_diacritics(disp_norm).upper().strip()
                # check exact/ ascii
                if disp_norm in face_info_norm_map:
                    matched = face_info_norm_map[disp_norm][1]
                    how = "matched_by_display_exact"
                elif disp_ascii in face_info_ascii_map:
                    matched = face_info_ascii_map[disp_ascii][1]
                    how = "matched_by_display_ascii"
    if matched is None:
        # create placeholder so UI never shows "chưa có mô tả"
        display_name = label_display_norm.get(lbl_n, lbl_n)
        matched = f"(PLACEHOLDER) Vui lòng cập nhật mô tả cho {display_name} (label gốc: {lbl_n})."
        how = "placeholder_created"

    final_face_info[lbl_n] = matched
    mapping_debug.append((lbl_n, how))

# Print mapping debug
print("\n=== Mapping debug (label_raw -> how matched) ===")
for lbl_n, how in mapping_debug:
    print(f"  {lbl_n}  -> {how}")
print("If you see 'placeholder_created' for any label, please update face_info_user for that label.\n")

# ----------------- Validate model output size vs labels length -----------------
# get n_classes from model output
try:
    dummy = np.zeros((1,60,60,3), dtype=np.float32)
    preds_dummy = model.predict(dummy)
    n_classes = preds_dummy.shape[1]
except Exception:
    # fallback: try to get from last layer
    try:
        n_classes = model.output_shape[-1]
    except Exception:
        n_classes = None

if n_classes is not None and n_classes != len(labels_by_index):
    print("⚠️ CẢNH BÁO: số lớp model ({} ) khác số nhãn tìm được ({}).".format(n_classes, len(labels_by_index)))
    print("Điều này có thể làm kết quả bị lệch nếu nhãn_by_index không đúng thứ tự như model đã train.")
    # If mismatch, try to resize labels_by_index to n_classes
    if n_classes and len(labels_by_index) < n_classes:
        # pad with generic names
        for i in range(len(labels_by_index), n_classes):
            labels_by_index.append(f"class_{i}")
            final_face_info[f"class_{i}"] = f"(PLACEHOLDER) class_{i}"
        print("Đã bổ sung nhãn generic đến đủ số lớp model.")
    elif n_classes and len(labels_by_index) > n_classes:
        labels_by_index = labels_by_index[:n_classes]
        print("Đã cắt nhãn_by_index để khớp số lớp model.")

# Recompute final normalized labels_by_index
labels_by_index = [norm_nfc(x) for x in labels_by_index]

# ----------------- Hàm dự đoán dùng chung -----------------
def predict_from_pil(img_pil, return_top3=False):
    # resize to model expected (you used 60x60)
    img_resized = img_pil.convert("RGB").resize((60,60))
    x = np.array(img_resized) / 255.0
    x = np.expand_dims(x, axis=0)

    preds = model.predict(x)  # shape (1, n_classes)
    probs = preds[0]
    class_idx = int(np.argmax(probs))
    confidence = float(probs[class_idx])

    # safe index -> label
    if class_idx < len(labels_by_index):
        label_raw = labels_by_index[class_idx]
    else:
        label_raw = f"class_{class_idx}"

    label_raw_n = norm_nfc(label_raw)
    label_show = label_display_norm.get(label_raw_n, label_raw_n)  # nếu có mapping hiển thị dùng nó

    description = final_face_info.get(label_raw_n, f"(PLACEHOLDER) Hiện chưa có mô tả cho {label_show}.")

    # top-3
    top3 = []
    try:
        top3_idx = np.argsort(probs)[-3:][::-1]
        for i in top3_idx:
            lbl = labels_by_index[i] if i < len(labels_by_index) else f"class_{i}"
            top3.append((lbl, float(probs[i])))
    except Exception:
        pass

    if return_top3:
        return img_resized, label_show, round(confidence*100,2), description, top3
    else:
        return img_resized, label_show, round(confidence*100,2), description

# ----------------- ĐOẠN 1: upload + dự đoán nhanh (in debug) -----------------
print("\n--- UPLOAD 1 ảnh để test nhanh ---")
uploaded = files.upload()
img_path = list(uploaded.keys())[0]
img = Image.open(img_path)

img_resized, person, conf, description, top3 = predict_from_pil(img, return_top3=True)
print("Dự đoán (hiển thị):", person)
print("Độ tin cậy:", conf, "%")
print("Mô tả (đã map):", description)
print("Top-3 (label_raw,prob):", top3)

# Hiển thị ảnh gốc
plt.imshow(np.array(img))
plt.title(f"Dự đoán: {person} ({conf:.2f}%)")
plt.axis("off")
plt.show()

# ----------------- ĐOẠN 2: Gradio UI -----------------
def predict_face_gradio(inp_img):
    img_resized, person, conf, description = predict_from_pil(inp_img, return_top3=False)
    # show confidence as string with percent
    conf_str = f"{conf:.2f}%"
    return img_resized, person, conf_str, description

def reset_image():
    return None, None, "", "", ""

css_style = """
body { background: linear-gradient(to right, #ffe0e0, #fff8e1); font-family: 'Poppins', sans-serif;}
h1 { color: #d81b60; font-family: 'Orbitron', sans-serif; font-size: 38px;}
#predict-btn, #reset-btn { background-color: #f06292; color: #fff; font-weight: bold; font-size: 18px;}
.gr-button {border-radius: 20px; padding: 12px 25px;}
.gr-box { border: 2px solid #d81b60; border-radius: 20px; padding: 15px; background-color: rgba(255,255,255,0.9); }
"""

with gr.Blocks(css=css_style) as demo:
    gr.Markdown("<h1 style='text-align:center;'>Ứng dụng nhận diện khuôn mặt 👤 (Fixed mapping)</h1>")

    with gr.Row():
        with gr.Column():
            img_input = gr.Image(type="pil", label="Chọn ảnh hoặc kéo thả khuôn mặt vào đây")
            btn_predict = gr.Button("Nhận diện 👤", elem_id="predict-btn")
            btn_reset = gr.Button("Chọn ảnh khác 🔄", elem_id="reset-btn")
        with gr.Column():
            img_resized_output = gr.Image(type="pil", label="Ảnh đã resize (60x60)")
            label_output = gr.Textbox(label="Tên người dự đoán", interactive=False)
            confidence_output = gr.Textbox(label="Độ chính xác (%)", interactive=False)
            description_output = gr.Textbox(label="Mô tả chi tiết", interactive=False, lines=6)

    btn_predict.click(
        predict_face_gradio,
        inputs=img_input,
        outputs=[img_resized_output, label_output, confidence_output, description_output]
    )

    btn_reset.click(
        lambda: (None, None, "", ""),
        inputs=None,
        outputs=[img_input, img_resized_output, label_output, confidence_output]
    )

print("Launching Gradio app (share=True)...")
demo.launch(share=True)