# -*- coding: utf-8 -*-
"""Untitled29.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QL1sE6IlPHliMzV0M-iimTfAJ_qchcVB
"""

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 1) Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

import os
src_path = "/content/drive/MyDrive/data_mau"

# Ki·ªÉm tra th∆∞ m·ª•c
print("Classes:", os.listdir(src_path))

# 2) Import + t·∫°o generator v·ªõi resize 60x60 v√† t√°ch validation 20%
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,  # 20% ·∫£nh l√†m validation
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

train_generator = datagen.flow_from_directory(
    src_path,
    target_size=(60, 60),
    batch_size=32,
    class_mode='categorical',
    subset='training',   # train subset
    shuffle=True
)

val_generator = datagen.flow_from_directory(
    src_path,
    target_size=(60, 60),
    batch_size=32,
    class_mode='categorical',
    subset='validation',  # validation subset
    shuffle=False
)

# 3) Build CNN model
from tensorflow.keras import layers, models

num_classes = train_generator.num_classes

model = models.Sequential([
    layers.Input(shape=(60, 60, 3)),
    layers.Conv2D(32, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(num_classes, activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

# 4) Train model
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs= 100
)
model.save('final_model.h5')

# =============================
# FIX: ƒê·ªìng b·ªô nh√£n model <-> t√™n hi·ªÉn th·ªã <-> m√¥ t·∫£ (robust)
# D√°n nguy√™n v√†o Colab v√† ch·∫°y
# =============================

from google.colab import files
import os, json, unicodedata, glob
import numpy as np
import matplotlib.pyplot as plt
import gradio as gr
from PIL import Image
from tensorflow.keras.models import load_model

# ---------- C·∫•u h√¨nh (ch·ªâ ƒë·ªïi model_path n·∫øu c·∫ßn) ----------
model_path = "final_model.h5"
# N·∫øu b·∫°n c√≥ fallback labels v√¨ ch·∫Øc ch·∫Øn bi·∫øt th·ª© t·ª± model training, gi·ªØ trong labels_fallback.
# Nh∆∞ng code s·∫Ω ∆∞u ti√™n t√¨m class_indices t·ª´ train_generator n·∫øu c√≥.
labels_fallback = ["NHUAN", "LINH", "DAT"]

# N·∫øu b·∫°n ƒë√£ c√≥ face_info (m√¥ t·∫£) v·ªõi key d·∫°ng c√≥ d·∫•u ho·∫∑c kh√¥ng d·∫•u,
# paste v√†o ƒë√¢y ch√≠nh x√°c nh∆∞ b·∫°n ƒë√£ vi·∫øt (m√¨nh s·∫Ω auto map).
face_info_user = {
    "NHU·∫¨N": "Ho√†ng Nhu·∫≠n v·ªõi MSSV 31241024710, l√† m·ªôt ng∆∞·ªùi ƒëam m√™ c√¥ng ngh·ªá v√† th·ªÉ thao. Nam th∆∞·ªùng d√†nh th·ªùi gian ƒë·ªÉ h·ªçc t·∫≠p, t√¨m hi·ªÉu v·ªÅ c√°c m·∫°ch ƒëi·ªán v√† h·ªá th·ªëng th√¥ng minh v√† c≈©ng tham gia c√°c tr·∫≠n b√≥ng chuy·ªÅn s√¥i ƒë·ªông. V·ªÅ ngo·∫°i h√¨nh, m√¨nh cao kho·∫£ng 170 cm v√† n·∫∑ng 80 kg. L√† m·ªôt ng∆∞·ªùi s·ªëng h√≤a ƒë·ªìng, s√¥i n·ªïi, nhi·ªát t√¨nh, lu√¥n s·∫µn s√†ng l·∫Øng nghe v√† h·ªó tr·ª£ b·∫°n b√® trong h·ªçc t·∫≠p v√† c√°c d·ª± √°n s√°ng t·∫°o.",
    "LINH": "Th√πy Linh, hi·ªán l√† sinh vi√™n v·ªõi MSSV 31241023167. Linh c√≥ ni·ªÅm ƒëam m√™ v·ªõi ƒë·ªçc s√°ch v√† ch∆°i c·∫ßu l√¥ng, v√† th∆∞·ªùng d√†nh th·ªùi gian r·∫£nh ƒë·ªÉ kh√°m ph√° th√™m nh·ªØng k·ªπ nƒÉng m·ªõi ho·∫∑c th·ª≠ s·ª©c v·ªõi nh·ªØng tr√≤ ch∆°i s√°ng t·∫°o. V·ªÅ ngo·∫°i h√¨nh, m√¨nh cao kho·∫£ng 160 cm v√† n·∫∑ng 48 kg. M√¨nh l√† ng∆∞·ªùi h√≤a ƒë·ªìng, th√≠ch k·∫øt n·ªëi v·ªõi m·ªçi ng∆∞·ªùi v√† lu√¥n s·∫µn s√†ng tham gia c√°c ho·∫°t ƒë·ªông nh√≥m ho·∫∑c d·ª± √°n m·ªõi ƒë·ªÉ tr·∫£i nghi·ªám v√† ph√°t tri·ªÉn b·∫£n th√¢n.",
    "ƒê·∫†T": "Tu·∫•n ƒê·∫°t ‚Äì MSSV 31241021943 ‚Äì l√† m·ªôt ng∆∞·ªùi tr·∫ª ƒë·∫ßy nhi·ªát huy·∫øt, lu√¥n nu√¥i d∆∞·ª°ng ni·ªÅm ƒëam m√™ v·ªõi c√¥ng ngh·ªá v√† th·ªÉ thao. Ngo√†i gi·ªù h·ªçc, ƒê·∫°t th∆∞·ªùng d√†nh th·ªùi gian ƒë·ªÉ kh√°m ph√° tri th·ª©c m·ªõi, t√¨m hi·ªÉu v·ªÅ cu·ªôc s·ªëng v√† m·ªü r·ªông g√≥c nh√¨n. V·ªõi ngo·∫°i h√¨nh c√¢n ƒë·ªëi (cao kho·∫£ng 1m70, n·∫∑ng 65kg), ƒê·∫°t mang phong th√°i nƒÉng ƒë·ªông, kh·ªèe kho·∫Øn. Trong giao ti·∫øp, ƒê·∫°t ƒë∆∞·ª£c bi·∫øt ƒë·∫øn l√† ng∆∞·ªùi h√≤a ƒë·ªìng, s√¥i n·ªïi v√† nhi·ªát t√¨nh. Kh√¥ng ch·ªâ hƒÉng h√°i tham gia ho·∫°t ƒë·ªông t·∫≠p th·ªÉ, ƒê·∫°t c√≤n lu√¥n s·∫µn s√†ng l·∫Øng nghe, chia s·∫ª v√† h·ªó tr·ª£ b·∫°n b√® trong h·ªçc t·∫≠p c≈©ng nh∆∞ c√°c d·ª± √°n s√°ng t·∫°o."
}

# N·∫øu b·∫°n mu·ªën hi·ªÉn th·ªã t√™n c√≥ d·∫•u (ƒë·∫πp) kh√°c v·ªõi nh√£n g·ªëc, khai b√°o ·ªü ƒë√¢y.
# Key ph·∫£i l√† nh√£n g·ªëc (nh∆∞ 'NHUAN'), value l√† t√™n hi·ªÉn th·ªã 'NHU·∫¨N'.
label_display_user = {
    "NHUAN": "NHU·∫¨N",
    "LINH": "LINH",
    "DAT": "ƒê·∫†T"
}

# ----------------- Helpers -----------------
def norm_nfc(s):
    if s is None:
        return None
    return unicodedata.normalize("NFC", str(s)).strip()

def remove_diacritics(s):
    if s is None:
        return None
    s = unicodedata.normalize("NFD", str(s))
    return "".join(ch for ch in s if not unicodedata.combining(ch))

# Load model
print("Loading model:", model_path)
model = load_model(model_path)
print("Model loaded.")

# ----------------- T√¨m labels theo index (an to√†n) -----------------
def build_labels_by_index():
    # 1) N·∫øu train_generator c√≥ s·∫µn trong scope (n·∫øu b·∫°n ƒëang ch·∫°y cell tr∆∞·ªõc ƒë√£ t·∫°o train_generator)
    try:
        if 'train_generator' in globals():
            ci = train_generator.class_indices
            print("Found train_generator.class_indices:", ci)
            # build list index -> label
            max_idx = max(ci.values()) if len(ci)>0 else -1
            labels_by_index = [None]*(max_idx+1)
            for k,v in ci.items():
                labels_by_index[v] = k
            return labels_by_index
    except Exception as e:
        print("train_generator lookup error:", e)

    # 2) Try loading class_indices.json if exists
    for fname in ["class_indices.json", "class_indices.txt", "class_indices.pkl"]:
        if os.path.exists(fname):
            try:
                with open(fname, "r", encoding="utf-8") as f:
                    data = json.load(f)
                # expect dict label->index
                max_idx = max(data.values())
                labels_by_index = [None]*(max_idx+1)
                for k,v in data.items():
                    labels_by_index[v] = k
                print("Loaded class indices from", fname)
                return labels_by_index
            except Exception:
                pass

    # 3) Try scanning folders common: 'train', 'data', 'dataset'
    for d in ["./train", "./data", "./dataset", "./training", "./images"]:
        if os.path.isdir(d):
            sub = [name for name in os.listdir(d) if os.path.isdir(os.path.join(d,name))]
            if sub:
                sub_sorted = sorted(sub)
                print("Found training subfolders in", d, "->", sub_sorted)
                # CAVEAT: order might not match original training but best-effort
                return sub_sorted

    # 4) Fallback to labels_fallback if defined
    if labels_fallback and isinstance(labels_fallback, list):
        print("Using labels_fallback (developer-provided):", labels_fallback)
        return labels_fallback

    # 5) Last resort: build generic names from number of classes model outputs
    try:
        # pass a dummy through model to get output size
        dummy = np.zeros((1,60,60,3), dtype=np.float32)
        preds = model.predict(dummy)
        n = preds.shape[1]
        generic = [f"class_{i}" for i in range(n)]
        print("No labels found; using generic labels:", generic)
        return generic
    except Exception as e:
        print("Unable to infer labels_by_index:", e)
        return []

labels_by_index = build_labels_by_index()
labels_by_index = [norm_nfc(lbl) for lbl in labels_by_index]  # normalize
print("Labels by index (final):", labels_by_index)

# ----------------- Chu·∫©n ho√° face_info v√† map keys -----------------
# Normalize user's face_info keys for flexible matching
face_info_norm_map = {}   # key_norm -> (orig_key, value)
for k,v in face_info_user.items():
    kn = norm_nfc(k)
    face_info_norm_map[kn] = (k, v)

# Build ascii (no-diacritics) map to match NHU·∫¨N <-> NHUAN
face_info_ascii_map = {}
for kn, (origk, val) in face_info_norm_map.items():
    ascii_k = remove_diacritics(kn).upper().strip()
    face_info_ascii_map[ascii_k] = (origk, val)

# Normalize label_display
label_display_norm = {}
for k,v in label_display_user.items():
    label_display_norm[norm_nfc(k)] = v

# Final mapping: label_raw -> description
final_face_info = {}
mapping_debug = []  # list of tuples for print: (label_raw, matched_key_used or None, how)

for lbl in labels_by_index:
    lbl_n = norm_nfc(lbl)
    lbl_ascii = remove_diacritics(lbl_n).upper().strip()

    matched = None
    how = None

    # 1) Exact match by normalized key (face_info has key identical to label raw)
    if lbl_n in face_info_norm_map:
        matched = face_info_norm_map[lbl_n][1]
        how = "exact_norm"
    else:
        # 2) Match by ascii (remove diacritics)
        if lbl_ascii in face_info_ascii_map:
            matched = face_info_ascii_map[lbl_ascii][1]
            how = "matched_by_ascii"
        else:
            # 3) Try matching by label_display value if user used display name as key in face_info
            disp = label_display_norm.get(lbl_n)
            if disp:
                disp_norm = norm_nfc(disp)
                disp_ascii = remove_diacritics(disp_norm).upper().strip()
                # check exact/ ascii
                if disp_norm in face_info_norm_map:
                    matched = face_info_norm_map[disp_norm][1]
                    how = "matched_by_display_exact"
                elif disp_ascii in face_info_ascii_map:
                    matched = face_info_ascii_map[disp_ascii][1]
                    how = "matched_by_display_ascii"
    if matched is None:
        # create placeholder so UI never shows "ch∆∞a c√≥ m√¥ t·∫£"
        display_name = label_display_norm.get(lbl_n, lbl_n)
        matched = f"(PLACEHOLDER) Vui l√≤ng c·∫≠p nh·∫≠t m√¥ t·∫£ cho {display_name} (label g·ªëc: {lbl_n})."
        how = "placeholder_created"

    final_face_info[lbl_n] = matched
    mapping_debug.append((lbl_n, how))

# Print mapping debug
print("\n=== Mapping debug (label_raw -> how matched) ===")
for lbl_n, how in mapping_debug:
    print(f"  {lbl_n}  -> {how}")
print("If you see 'placeholder_created' for any label, please update face_info_user for that label.\n")

# ----------------- Validate model output size vs labels length -----------------
# get n_classes from model output
try:
    dummy = np.zeros((1,60,60,3), dtype=np.float32)
    preds_dummy = model.predict(dummy)
    n_classes = preds_dummy.shape[1]
except Exception:
    # fallback: try to get from last layer
    try:
        n_classes = model.output_shape[-1]
    except Exception:
        n_classes = None

if n_classes is not None and n_classes != len(labels_by_index):
    print("‚ö†Ô∏è C·∫¢NH B√ÅO: s·ªë l·ªõp model ({} ) kh√°c s·ªë nh√£n t√¨m ƒë∆∞·ª£c ({}).".format(n_classes, len(labels_by_index)))
    print("ƒêi·ªÅu n√†y c√≥ th·ªÉ l√†m k·∫øt qu·∫£ b·ªã l·ªách n·∫øu nh√£n_by_index kh√¥ng ƒë√∫ng th·ª© t·ª± nh∆∞ model ƒë√£ train.")
    # If mismatch, try to resize labels_by_index to n_classes
    if n_classes and len(labels_by_index) < n_classes:
        # pad with generic names
        for i in range(len(labels_by_index), n_classes):
            labels_by_index.append(f"class_{i}")
            final_face_info[f"class_{i}"] = f"(PLACEHOLDER) class_{i}"
        print("ƒê√£ b·ªï sung nh√£n generic ƒë·∫øn ƒë·ªß s·ªë l·ªõp model.")
    elif n_classes and len(labels_by_index) > n_classes:
        labels_by_index = labels_by_index[:n_classes]
        print("ƒê√£ c·∫Øt nh√£n_by_index ƒë·ªÉ kh·ªõp s·ªë l·ªõp model.")

# Recompute final normalized labels_by_index
labels_by_index = [norm_nfc(x) for x in labels_by_index]

# ----------------- H√†m d·ª± ƒëo√°n d√πng chung -----------------
def predict_from_pil(img_pil, return_top3=False):
    # resize to model expected (you used 60x60)
    img_resized = img_pil.convert("RGB").resize((60,60))
    x = np.array(img_resized) / 255.0
    x = np.expand_dims(x, axis=0)

    preds = model.predict(x)  # shape (1, n_classes)
    probs = preds[0]
    class_idx = int(np.argmax(probs))
    confidence = float(probs[class_idx])

    # safe index -> label
    if class_idx < len(labels_by_index):
        label_raw = labels_by_index[class_idx]
    else:
        label_raw = f"class_{class_idx}"

    label_raw_n = norm_nfc(label_raw)
    label_show = label_display_norm.get(label_raw_n, label_raw_n)  # n·∫øu c√≥ mapping hi·ªÉn th·ªã d√πng n√≥

    description = final_face_info.get(label_raw_n, f"(PLACEHOLDER) Hi·ªán ch∆∞a c√≥ m√¥ t·∫£ cho {label_show}.")

    # top-3
    top3 = []
    try:
        top3_idx = np.argsort(probs)[-3:][::-1]
        for i in top3_idx:
            lbl = labels_by_index[i] if i < len(labels_by_index) else f"class_{i}"
            top3.append((lbl, float(probs[i])))
    except Exception:
        pass

    if return_top3:
        return img_resized, label_show, round(confidence*100,2), description, top3
    else:
        return img_resized, label_show, round(confidence*100,2), description

# ----------------- ƒêO·∫†N 1: upload + d·ª± ƒëo√°n nhanh (in debug) -----------------
print("\n--- UPLOAD 1 ·∫£nh ƒë·ªÉ test nhanh ---")
uploaded = files.upload()
img_path = list(uploaded.keys())[0]
img = Image.open(img_path)

img_resized, person, conf, description, top3 = predict_from_pil(img, return_top3=True)
print("D·ª± ƒëo√°n (hi·ªÉn th·ªã):", person)
print("ƒê·ªô tin c·∫≠y:", conf, "%")
print("M√¥ t·∫£ (ƒë√£ map):", description)
print("Top-3 (label_raw,prob):", top3)

# Hi·ªÉn th·ªã ·∫£nh g·ªëc
plt.imshow(np.array(img))
plt.title(f"D·ª± ƒëo√°n: {person} ({conf:.2f}%)")
plt.axis("off")
plt.show()

# ----------------- ƒêO·∫†N 2: Gradio UI -----------------
def predict_face_gradio(inp_img):
    img_resized, person, conf, description = predict_from_pil(inp_img, return_top3=False)
    # show confidence as string with percent
    conf_str = f"{conf:.2f}%"
    return img_resized, person, conf_str, description

def reset_image():
    return None, None, "", "", ""

css_style = """
body { background: linear-gradient(to right, #ffe0e0, #fff8e1); font-family: 'Poppins', sans-serif;}
h1 { color: #d81b60; font-family: 'Orbitron', sans-serif; font-size: 38px;}
#predict-btn, #reset-btn { background-color: #f06292; color: #fff; font-weight: bold; font-size: 18px;}
.gr-button {border-radius: 20px; padding: 12px 25px;}
.gr-box { border: 2px solid #d81b60; border-radius: 20px; padding: 15px; background-color: rgba(255,255,255,0.9); }
"""

with gr.Blocks(css=css_style) as demo:
    gr.Markdown("<h1 style='text-align:center;'>·ª®ng d·ª•ng nh·∫≠n di·ªán khu√¥n m·∫∑t üë§ (Fixed mapping)</h1>")

    with gr.Row():
        with gr.Column():
            img_input = gr.Image(type="pil", label="Ch·ªçn ·∫£nh ho·∫∑c k√©o th·∫£ khu√¥n m·∫∑t v√†o ƒë√¢y")
            btn_predict = gr.Button("Nh·∫≠n di·ªán üë§", elem_id="predict-btn")
            btn_reset = gr.Button("Ch·ªçn ·∫£nh kh√°c üîÑ", elem_id="reset-btn")
        with gr.Column():
            img_resized_output = gr.Image(type="pil", label="·∫¢nh ƒë√£ resize (60x60)")
            label_output = gr.Textbox(label="T√™n ng∆∞·ªùi d·ª± ƒëo√°n", interactive=False)
            confidence_output = gr.Textbox(label="ƒê·ªô ch√≠nh x√°c (%)", interactive=False)
            description_output = gr.Textbox(label="M√¥ t·∫£ chi ti·∫øt", interactive=False, lines=6)

    btn_predict.click(
        predict_face_gradio,
        inputs=img_input,
        outputs=[img_resized_output, label_output, confidence_output, description_output]
    )

    btn_reset.click(
        lambda: (None, None, "", ""),
        inputs=None,
        outputs=[img_input, img_resized_output, label_output, confidence_output]
    )

print("Launching Gradio app (share=True)...")
demo.launch(share=True)