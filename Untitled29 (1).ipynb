{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VT9vahmQWPFT"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "src_path = \"/content/drive/MyDrive/data_mau\"\n",
        "\n",
        "# Kiểm tra thư mục\n",
        "print(\"Classes:\", os.listdir(src_path))\n",
        "\n",
        "# 2) Import + tạo generator với resize 60x60 và tách validation 20%\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,  # 20% ảnh làm validation\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    src_path,\n",
        "    target_size=(60, 60),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training',   # train subset\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    src_path,\n",
        "    target_size=(60, 60),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',  # validation subset\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# 3) Build CNN model\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "num_classes = train_generator.num_classes\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(60, 60, 3)),\n",
        "    layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 4) Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs= 200\n",
        ")\n",
        "model.save('final_model.h5')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kwmffGgBWPpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# FIX: Đồng bộ nhãn model <-> tên hiển thị <-> mô tả (robust)\n",
        "# Dán nguyên vào Colab và chạy\n",
        "# =============================\n",
        "\n",
        "from google.colab import files\n",
        "import os, json, unicodedata, glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# ---------- Cấu hình (chỉ đổi model_path nếu cần) ----------\n",
        "model_path = \"final_model.h5\"\n",
        "# Nếu bạn có fallback labels vì chắc chắn biết thứ tự model training, giữ trong labels_fallback.\n",
        "# Nhưng code sẽ ưu tiên tìm class_indices từ train_generator nếu có.\n",
        "labels_fallback = [\"NHUAN\", \"LINH\", \"DAT\"]\n",
        "\n",
        "# Nếu bạn đã có face_info (mô tả) với key dạng có dấu hoặc không dấu,\n",
        "# paste vào đây chính xác như bạn đã viết (mình sẽ auto map).\n",
        "face_info_user = {\n",
        "    \"NHUẬN\": \"Hoàng Nhuận với MSSV 31241024710, là một người đam mê công nghệ và thể thao. Nam thường dành thời gian để học tập, tìm hiểu về các mạch điện và hệ thống thông minh và cũng tham gia các trận bóng chuyền sôi động. Về ngoại hình, mình cao khoảng 170 cm và nặng 80 kg. Là một người sống hòa đồng, sôi nổi, nhiệt tình, luôn sẵn sàng lắng nghe và hỗ trợ bạn bè trong học tập và các dự án sáng tạo.\",\n",
        "    \"LINH\": \"Thùy Linh, hiện là sinh viên với MSSV 31241023167. Linh có niềm đam mê với đọc sách và chơi cầu lông, và thường dành thời gian rảnh để khám phá thêm những kỹ năng mới hoặc thử sức với những trò chơi sáng tạo. Về ngoại hình, mình cao khoảng 160 cm và nặng 48 kg. Mình là người hòa đồng, thích kết nối với mọi người và luôn sẵn sàng tham gia các hoạt động nhóm hoặc dự án mới để trải nghiệm và phát triển bản thân.\",\n",
        "    \"ĐẠT\": \"Tuấn Đạt – MSSV 31241021943 – là một người trẻ đầy nhiệt huyết, luôn nuôi dưỡng niềm đam mê với công nghệ và thể thao. Ngoài giờ học, Đạt thường dành thời gian để khám phá tri thức mới, tìm hiểu về cuộc sống và mở rộng góc nhìn. Với ngoại hình cân đối (cao khoảng 1m70, nặng 65kg), Đạt mang phong thái năng động, khỏe khoắn. Trong giao tiếp, Đạt được biết đến là người hòa đồng, sôi nổi và nhiệt tình. Không chỉ hăng hái tham gia hoạt động tập thể, Đạt còn luôn sẵn sàng lắng nghe, chia sẻ và hỗ trợ bạn bè trong học tập cũng như các dự án sáng tạo.\"\n",
        "}\n",
        "\n",
        "# Nếu bạn muốn hiển thị tên có dấu (đẹp) khác với nhãn gốc, khai báo ở đây.\n",
        "# Key phải là nhãn gốc (như 'NHUAN'), value là tên hiển thị 'NHUẬN'.\n",
        "label_display_user = {\n",
        "    \"NHUAN\": \"NHUẬN\",\n",
        "    \"LINH\": \"LINH\",\n",
        "    \"DAT\": \"ĐẠT\"\n",
        "}\n",
        "\n",
        "# ----------------- Helpers -----------------\n",
        "def norm_nfc(s):\n",
        "    if s is None:\n",
        "        return None\n",
        "    return unicodedata.normalize(\"NFC\", str(s)).strip()\n",
        "\n",
        "def remove_diacritics(s):\n",
        "    if s is None:\n",
        "        return None\n",
        "    s = unicodedata.normalize(\"NFD\", str(s))\n",
        "    return \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
        "\n",
        "# Load model\n",
        "print(\"Loading model:\", model_path)\n",
        "model = load_model(model_path)\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "# ----------------- Tìm labels theo index (an toàn) -----------------\n",
        "def build_labels_by_index():\n",
        "    # 1) Nếu train_generator có sẵn trong scope (nếu bạn đang chạy cell trước đã tạo train_generator)\n",
        "    try:\n",
        "        if 'train_generator' in globals():\n",
        "            ci = train_generator.class_indices\n",
        "            print(\"Found train_generator.class_indices:\", ci)\n",
        "            # build list index -> label\n",
        "            max_idx = max(ci.values()) if len(ci)>0 else -1\n",
        "            labels_by_index = [None]*(max_idx+1)\n",
        "            for k,v in ci.items():\n",
        "                labels_by_index[v] = k\n",
        "            return labels_by_index\n",
        "    except Exception as e:\n",
        "        print(\"train_generator lookup error:\", e)\n",
        "\n",
        "    # 2) Try loading class_indices.json if exists\n",
        "    for fname in [\"class_indices.json\", \"class_indices.txt\", \"class_indices.pkl\"]:\n",
        "        if os.path.exists(fname):\n",
        "            try:\n",
        "                with open(fname, \"r\", encoding=\"utf-8\") as f:\n",
        "                    data = json.load(f)\n",
        "                # expect dict label->index\n",
        "                max_idx = max(data.values())\n",
        "                labels_by_index = [None]*(max_idx+1)\n",
        "                for k,v in data.items():\n",
        "                    labels_by_index[v] = k\n",
        "                print(\"Loaded class indices from\", fname)\n",
        "                return labels_by_index\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    # 3) Try scanning folders common: 'train', 'data', 'dataset'\n",
        "    for d in [\"./train\", \"./data\", \"./dataset\", \"./training\", \"./images\"]:\n",
        "        if os.path.isdir(d):\n",
        "            sub = [name for name in os.listdir(d) if os.path.isdir(os.path.join(d,name))]\n",
        "            if sub:\n",
        "                sub_sorted = sorted(sub)\n",
        "                print(\"Found training subfolders in\", d, \"->\", sub_sorted)\n",
        "                # CAVEAT: order might not match original training but best-effort\n",
        "                return sub_sorted\n",
        "\n",
        "    # 4) Fallback to labels_fallback if defined\n",
        "    if labels_fallback and isinstance(labels_fallback, list):\n",
        "        print(\"Using labels_fallback (developer-provided):\", labels_fallback)\n",
        "        return labels_fallback\n",
        "\n",
        "    # 5) Last resort: build generic names from number of classes model outputs\n",
        "    try:\n",
        "        # pass a dummy through model to get output size\n",
        "        dummy = np.zeros((1,60,60,3), dtype=np.float32)\n",
        "        preds = model.predict(dummy)\n",
        "        n = preds.shape[1]\n",
        "        generic = [f\"class_{i}\" for i in range(n)]\n",
        "        print(\"No labels found; using generic labels:\", generic)\n",
        "        return generic\n",
        "    except Exception as e:\n",
        "        print(\"Unable to infer labels_by_index:\", e)\n",
        "        return []\n",
        "\n",
        "labels_by_index = build_labels_by_index()\n",
        "labels_by_index = [norm_nfc(lbl) for lbl in labels_by_index]  # normalize\n",
        "print(\"Labels by index (final):\", labels_by_index)\n",
        "\n",
        "# ----------------- Chuẩn hoá face_info và map keys -----------------\n",
        "# Normalize user's face_info keys for flexible matching\n",
        "face_info_norm_map = {}   # key_norm -> (orig_key, value)\n",
        "for k,v in face_info_user.items():\n",
        "    kn = norm_nfc(k)\n",
        "    face_info_norm_map[kn] = (k, v)\n",
        "\n",
        "# Build ascii (no-diacritics) map to match NHUẬN <-> NHUAN\n",
        "face_info_ascii_map = {}\n",
        "for kn, (origk, val) in face_info_norm_map.items():\n",
        "    ascii_k = remove_diacritics(kn).upper().strip()\n",
        "    face_info_ascii_map[ascii_k] = (origk, val)\n",
        "\n",
        "# Normalize label_display\n",
        "label_display_norm = {}\n",
        "for k,v in label_display_user.items():\n",
        "    label_display_norm[norm_nfc(k)] = v\n",
        "\n",
        "# Final mapping: label_raw -> description\n",
        "final_face_info = {}\n",
        "mapping_debug = []  # list of tuples for print: (label_raw, matched_key_used or None, how)\n",
        "\n",
        "for lbl in labels_by_index:\n",
        "    lbl_n = norm_nfc(lbl)\n",
        "    lbl_ascii = remove_diacritics(lbl_n).upper().strip()\n",
        "\n",
        "    matched = None\n",
        "    how = None\n",
        "\n",
        "    # 1) Exact match by normalized key (face_info has key identical to label raw)\n",
        "    if lbl_n in face_info_norm_map:\n",
        "        matched = face_info_norm_map[lbl_n][1]\n",
        "        how = \"exact_norm\"\n",
        "    else:\n",
        "        # 2) Match by ascii (remove diacritics)\n",
        "        if lbl_ascii in face_info_ascii_map:\n",
        "            matched = face_info_ascii_map[lbl_ascii][1]\n",
        "            how = \"matched_by_ascii\"\n",
        "        else:\n",
        "            # 3) Try matching by label_display value if user used display name as key in face_info\n",
        "            disp = label_display_norm.get(lbl_n)\n",
        "            if disp:\n",
        "                disp_norm = norm_nfc(disp)\n",
        "                disp_ascii = remove_diacritics(disp_norm).upper().strip()\n",
        "                # check exact/ ascii\n",
        "                if disp_norm in face_info_norm_map:\n",
        "                    matched = face_info_norm_map[disp_norm][1]\n",
        "                    how = \"matched_by_display_exact\"\n",
        "                elif disp_ascii in face_info_ascii_map:\n",
        "                    matched = face_info_ascii_map[disp_ascii][1]\n",
        "                    how = \"matched_by_display_ascii\"\n",
        "    if matched is None:\n",
        "        # create placeholder so UI never shows \"chưa có mô tả\"\n",
        "        display_name = label_display_norm.get(lbl_n, lbl_n)\n",
        "        matched = f\"(PLACEHOLDER) Vui lòng cập nhật mô tả cho {display_name} (label gốc: {lbl_n}).\"\n",
        "        how = \"placeholder_created\"\n",
        "\n",
        "    final_face_info[lbl_n] = matched\n",
        "    mapping_debug.append((lbl_n, how))\n",
        "\n",
        "# Print mapping debug\n",
        "print(\"\\n=== Mapping debug (label_raw -> how matched) ===\")\n",
        "for lbl_n, how in mapping_debug:\n",
        "    print(f\"  {lbl_n}  -> {how}\")\n",
        "print(\"If you see 'placeholder_created' for any label, please update face_info_user for that label.\\n\")\n",
        "\n",
        "# ----------------- Validate model output size vs labels length -----------------\n",
        "# get n_classes from model output\n",
        "try:\n",
        "    dummy = np.zeros((1,60,60,3), dtype=np.float32)\n",
        "    preds_dummy = model.predict(dummy)\n",
        "    n_classes = preds_dummy.shape[1]\n",
        "except Exception:\n",
        "    # fallback: try to get from last layer\n",
        "    try:\n",
        "        n_classes = model.output_shape[-1]\n",
        "    except Exception:\n",
        "        n_classes = None\n",
        "\n",
        "if n_classes is not None and n_classes != len(labels_by_index):\n",
        "    print(\"⚠️ CẢNH BÁO: số lớp model ({} ) khác số nhãn tìm được ({}).\".format(n_classes, len(labels_by_index)))\n",
        "    print(\"Điều này có thể làm kết quả bị lệch nếu nhãn_by_index không đúng thứ tự như model đã train.\")\n",
        "    # If mismatch, try to resize labels_by_index to n_classes\n",
        "    if n_classes and len(labels_by_index) < n_classes:\n",
        "        # pad with generic names\n",
        "        for i in range(len(labels_by_index), n_classes):\n",
        "            labels_by_index.append(f\"class_{i}\")\n",
        "            final_face_info[f\"class_{i}\"] = f\"(PLACEHOLDER) class_{i}\"\n",
        "        print(\"Đã bổ sung nhãn generic đến đủ số lớp model.\")\n",
        "    elif n_classes and len(labels_by_index) > n_classes:\n",
        "        labels_by_index = labels_by_index[:n_classes]\n",
        "        print(\"Đã cắt nhãn_by_index để khớp số lớp model.\")\n",
        "\n",
        "# Recompute final normalized labels_by_index\n",
        "labels_by_index = [norm_nfc(x) for x in labels_by_index]\n",
        "\n",
        "# ----------------- Hàm dự đoán dùng chung -----------------\n",
        "def predict_from_pil(img_pil, return_top3=False):\n",
        "    # resize to model expected (you used 60x60)\n",
        "    img_resized = img_pil.convert(\"RGB\").resize((60,60))\n",
        "    x = np.array(img_resized) / 255.0\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    preds = model.predict(x)  # shape (1, n_classes)\n",
        "    probs = preds[0]\n",
        "    class_idx = int(np.argmax(probs))\n",
        "    confidence = float(probs[class_idx])\n",
        "\n",
        "    # safe index -> label\n",
        "    if class_idx < len(labels_by_index):\n",
        "        label_raw = labels_by_index[class_idx]\n",
        "    else:\n",
        "        label_raw = f\"class_{class_idx}\"\n",
        "\n",
        "    label_raw_n = norm_nfc(label_raw)\n",
        "    label_show = label_display_norm.get(label_raw_n, label_raw_n)  # nếu có mapping hiển thị dùng nó\n",
        "\n",
        "    description = final_face_info.get(label_raw_n, f\"(PLACEHOLDER) Hiện chưa có mô tả cho {label_show}.\")\n",
        "\n",
        "    # top-3\n",
        "    top3 = []\n",
        "    try:\n",
        "        top3_idx = np.argsort(probs)[-3:][::-1]\n",
        "        for i in top3_idx:\n",
        "            lbl = labels_by_index[i] if i < len(labels_by_index) else f\"class_{i}\"\n",
        "            top3.append((lbl, float(probs[i])))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    if return_top3:\n",
        "        return img_resized, label_show, round(confidence*100,2), description, top3\n",
        "    else:\n",
        "        return img_resized, label_show, round(confidence*100,2), description\n",
        "\n",
        "# ----------------- ĐOẠN 1: upload + dự đoán nhanh (in debug) -----------------\n",
        "print(\"\\n--- UPLOAD 1 ảnh để test nhanh ---\")\n",
        "uploaded = files.upload()\n",
        "img_path = list(uploaded.keys())[0]\n",
        "img = Image.open(img_path)\n",
        "\n",
        "img_resized, person, conf, description, top3 = predict_from_pil(img, return_top3=True)\n",
        "print(\"Dự đoán (hiển thị):\", person)\n",
        "print(\"Độ tin cậy:\", conf, \"%\")\n",
        "print(\"Mô tả (đã map):\", description)\n",
        "print(\"Top-3 (label_raw,prob):\", top3)\n",
        "\n",
        "# Hiển thị ảnh gốc\n",
        "plt.imshow(np.array(img))\n",
        "plt.title(f\"Dự đoán: {person} ({conf:.2f}%)\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# ----------------- ĐOẠN 2: Gradio UI -----------------\n",
        "def predict_face_gradio(inp_img):\n",
        "    img_resized, person, conf, description = predict_from_pil(inp_img, return_top3=False)\n",
        "    # show confidence as string with percent\n",
        "    conf_str = f\"{conf:.2f}%\"\n",
        "    return img_resized, person, conf_str, description\n",
        "\n",
        "def reset_image():\n",
        "    return None, None, \"\", \"\", \"\"\n",
        "\n",
        "css_style = \"\"\"\n",
        "body { background: linear-gradient(to right, #ffe0e0, #fff8e1); font-family: 'Poppins', sans-serif;}\n",
        "h1 { color: #d81b60; font-family: 'Orbitron', sans-serif; font-size: 38px;}\n",
        "#predict-btn, #reset-btn { background-color: #f06292; color: #fff; font-weight: bold; font-size: 18px;}\n",
        ".gr-button {border-radius: 20px; padding: 12px 25px;}\n",
        ".gr-box { border: 2px solid #d81b60; border-radius: 20px; padding: 15px; background-color: rgba(255,255,255,0.9); }\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=css_style) as demo:\n",
        "    gr.Markdown(\"<h1 style='text-align:center;'>Ứng dụng nhận diện khuôn mặt 👤 (Fixed mapping)</h1>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            img_input = gr.Image(type=\"pil\", label=\"Chọn ảnh hoặc kéo thả khuôn mặt vào đây\")\n",
        "            btn_predict = gr.Button(\"Nhận diện 👤\", elem_id=\"predict-btn\")\n",
        "            btn_reset = gr.Button(\"Chọn ảnh khác 🔄\", elem_id=\"reset-btn\")\n",
        "        with gr.Column():\n",
        "            img_resized_output = gr.Image(type=\"pil\", label=\"Ảnh đã resize (60x60)\")\n",
        "            label_output = gr.Textbox(label=\"Tên người dự đoán\", interactive=False)\n",
        "            confidence_output = gr.Textbox(label=\"Độ chính xác (%)\", interactive=False)\n",
        "            description_output = gr.Textbox(label=\"Mô tả chi tiết\", interactive=False, lines=6)\n",
        "\n",
        "    btn_predict.click(\n",
        "        predict_face_gradio,\n",
        "        inputs=img_input,\n",
        "        outputs=[img_resized_output, label_output, confidence_output, description_output]\n",
        "    )\n",
        "\n",
        "    btn_reset.click(\n",
        "        lambda: (None, None, \"\", \"\"),\n",
        "        inputs=None,\n",
        "        outputs=[img_input, img_resized_output, label_output, confidence_output]\n",
        "    )\n",
        "\n",
        "print(\"Launching Gradio app (share=True)...\")\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XyTD8U_WYHVb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
